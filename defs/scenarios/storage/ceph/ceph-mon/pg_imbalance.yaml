checks:
  cluster_has_osds_with_pgs_above_max:
    requires:
      property:
        path: hotsos.core.plugins.storage.ceph.CephCluster.osds_pgs_above_max
        ops: [[length_hint], [gt, 0]]
  cluster_has_osds_with_suboptimal_pgs:
    requires:
      property:
        path: hotsos.core.plugins.storage.ceph.CephCluster.osds_pgs_suboptimal
        ops: [[length_hint], [gt, 0]]
conclusions:
  cluster-osds-with-pgs-above-max:
    decision: cluster_has_osds_with_pgs_above_max
    raises:
      type: hotsos.core.issues.CephCrushError
      message: >-
        Found some Ceph osd(s) with > {limit} pgs - this is close to the hard
        limit at which point they will stop creating pgs and fail - please
        investigate.
      format-dict:
        limit: hotsos.core.plugins.storage.ceph.CephCluster.OSD_PG_MAX_LIMIT
  cluster-osds-with-suboptimal-pgs:
    decision: cluster_has_osds_with_suboptimal_pgs
    raises:
      type: hotsos.core.issues.CephCrushWarning
      message: >-
        Found some Ceph osd(s) whose pg count is > 30% outside the optimal range
        of {min}-{max} pgs. This could indicate poor data distribution across the
        cluster and result in performance degradation.
      format-dict:
        min: hotsos.core.plugins.storage.ceph.CephCluster.OSD_PG_OPTIMAL_NUM_MIN
        max: hotsos.core.plugins.storage.ceph.CephCluster.OSD_PG_OPTIMAL_NUM_MAX

